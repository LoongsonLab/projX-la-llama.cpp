# projX-la-llama.cpp

## 项目名称

llama.cpp的龙芯平台移植与优化

## 支持单位

龙芯中科技术股份有限公司、中国科学院计算技术研究所

## 项目描述

[llama.cpp](https://github.com/ggerganov/llama.cpp)是一个开源的推理程序，它支持包括Meta LLaMA等众多知名模型。本项目的目标是在LoongArch平台运行并优化之，定位和丰富该平台可以运行的模型组合。

## 所属赛道

2024全国大学生操作系统比赛的“OS功能挑战”赛道

## 参赛要求

* 以小组为单位参赛，最多三人一个小组，且小组成员是来自同一所高校的本科生或研究生
* 如学生参加了多个项目，参赛学生选择一个自己参加的项目参与评奖
* 请遵循“2024全国大学生操作系统比赛”的章程和技术方案要求

## 项目导师

* 殷时友
    - Email  yinshiyou-hf @ loongson.cn

## 难度

中-高

# License

GPL V3.0.

## 预期目标

* 实现llama.cpp在LoongArch平台的正常运行，确定用CPU运行能够达到可接受性能的模型组合。
* 通过各种软硬件方式对目标进行优化，争取提升模型的推理速度，扩大可用模型的范围。

## 参考资源

* [llama.cpp](https://github.com/ggerganov/llama.cpp) 
* [LoongArch docs](https://github.com/loongson/LoongArch-Documentation)。LoongArch相关文档，包括架构手册，ABI, 芯片手册等。

## 备注

龙芯中科可提供所需要的平台和相关资源
